{
  "verdict": "CHANGES_REQUIRED",
  "summary": "The design is close, but as written it has a couple of correctness/security flaws (req_hash feasibility, micro-USD arithmetic, and usage-report trust/idempotency) that will cause integration breakage or billing drift.",
  "blocking_issues": [
    {
      "location": "§3.1 JWT Validation Middleware — req_hash verification",
      "issue": "req_hash is defined as SHA-256 of the raw request body bytes, but the gateway is also expected to support streaming (SSE/WS) and Hono body parsing; in practice you often cannot both (a) stream the body to downstream handlers and (b) hash the exact raw bytes without buffering/consuming the stream. The SDD also skips req_hash for WebSocket upgrades, leaving the highest-value path unbound to the JWT.",
      "why_blocking": "This will either (1) break requests because the body stream is consumed by hashing, (2) force full buffering which can DOS memory and destroy streaming latency, or (3) silently disable req_hash on the paths that matter (WS), undermining the PRD’s request-binding security property. Any of these can cause production failures or a security gap that invalidates the integration contract.",
      "fix": "Make request binding compatible with streaming: bind the JWT to stable request metadata instead of raw body bytes, or define a canonicalization + buffering limit. Common options: (a) req_hash = hash(method + path + query + content-type + content-length + sha256(body)) but only for non-streaming JSON with a strict max size; (b) for streaming/chat, use a signed request_id + nonce + timestamp and require idempotency key, plus TLS + short exp; (c) for WS, require a JWT in the WS subprotocol or query param and bind to a server-issued challenge (nonce) echoed by client/arrakis. If you keep body hashing, explicitly implement a tee stream that hashes while forwarding, with hard caps and consistent byte-for-byte handling (no decompression, no charset transforms)."
    },
    {
      "location": "§3.3 Integer Micro-USD Budget — arithmetic rules & cross-language vectors",
      "issue": "The proposed conversion uses floating-point multiplication (`Math.floor(usd_precise * 1_000_000)` and Python `int(x * 1_000_000)`), which is not portable/deterministic across JS/Python for many decimal prices and token-based computations. Also, the remainder carry description is internally inconsistent: you floor to an integer micro already, so there is no fractional remainder to accumulate unless you’re tracking sub-micro units (nano/pico) or doing rational arithmetic.",
      "why_blocking": "This will cause billing drift between loa-finn and arrakis (and between JS and Python test harnesses), breaking the split-authority reconciliation model. In the worst case, tenants get over/under-charged and enforcement diverges, which is a project-failure class issue for a metered system.",
      "fix": "Eliminate floats from the cost path entirely. Compute cost in integer arithmetic from first principles: cost_micro = ceil_or_floor((tokens * price_micro_per_token_num) / price_micro_per_token_den) using BigInt in JS and int in Python, or use fixed-point with a higher base (e.g., nano-USD) and then convert. Define rounding explicitly per event (usually floor per event, reconcile with remainder in the same integer base). If you want remainder carry, track remainder in the same rational denominator (e.g., store `remainder_numer` with a fixed `denom`), not “>= 1 micro”. Update test vectors to be generated from integer/rational inputs (tokens, numerator/denominator pricing), not from decimal USD floats."
    },
    {
      "location": "§3.4 Usage Report Pipeline — idempotency, authenticity, and reconciliation semantics",
      "issue": "Usage reports are posted with a report_id ULID and “retry 3x then dead-letter”, but there is no defined idempotency behavior on the arrakis side (dedupe key, retention window), no signature/binding of the report payload to the original user JWT/trace, and no guarantee that reports are eventually delivered (local JSONL dead-letter is not durable in many deployments).",
      "why_blocking": "Without strict idempotency, retries can double-charge. Without durable delivery, arrakis enforcement will drift from loa-finn’s authoritative measurement, breaking split-authority. Without binding, a compromised loa-finn (or misconfigured environment) can forge/alter usage, which is catastrophic for billing and trust boundaries.",
      "fix": "Define the arrakis contract: (1) arrakis must enforce idempotency on `report_id` (or `(trace_id, request_id, model, attempt)`), with a clear TTL (e.g., 30–90 days) and atomic insert-or-ignore (Redis SETNX / DB unique index). (2) Make delivery durable: use a persistent queue (Redis stream, SQS, Kafka) or at minimum write dead-letter to durable storage (R2/S3) and add a replayer job. (3) Bind usage to the originating request: include the original user JWT `jti` (or a derived request_id signed by arrakis) and/or sign the usage payload with loa-finn’s S2S key (JWS over canonical JSON) so arrakis can verify integrity beyond transport TLS."
    },
    {
      "location": "§3.1 Dual-auth middleware chain — ambiguity between “JWT bearer” and “simple bearer”",
      "issue": "Both auth modes use `Authorization: Bearer ...` and the chain says “check for JWT first; if JWT validate; else fall back to existing bearer auth”. In practice, you cannot reliably distinguish a JWT from an opaque token without attempting JWT parsing/verification, and failure modes are ambiguous (e.g., malformed JWT vs opaque token). This can lead to incorrect auth decisions or confusing 401/403 behavior, especially if an opaque token happens to be three dot-separated segments.",
      "why_blocking": "This can lock out legitimate clients or, worse, accidentally accept an opaque token as a JWT in partial-parse paths if implementation is sloppy. It’s a common source of production auth outages during migration.",
      "fix": "Make the modes unambiguous at the protocol level: use different schemes (`Authorization: ArrakisJWT <jwt>` vs `Authorization: Bearer <opaque>`), or require JWTs on `/api/arrakis/*` and opaque tokens on `/api/direct/*`. If you must share the header, add a strict prefix inside the token (e.g., `jwt:<...>`), or require `typ`/`kid` presence and only treat as JWT if it passes a strict structural pre-check plus `iss/aud` match; otherwise treat as opaque. Document exact precedence and error mapping."
    },
    {
      "location": "§3.8 Ensemble Orchestrator — budget/abort interaction",
      "issue": "Budget enforcement says: “If one model exhausts budget, remaining models are aborted (not just the exceeded one).” This is incompatible with `best_of_n` where you need all results, and it can also cause systematic under-delivery if one slow/expensive model hits its per-model budget early. Additionally, cost is only known after completion for many providers; without mid-stream token accounting, ‘exhausts budget’ cannot be detected in time to prevent overspend.",
      "why_blocking": "This will make ensemble strategies unreliable (frequent aborts, inconsistent outputs) and can violate budget guarantees (overspend before detection). If ensemble is a core Phase 5 feature, this can fail acceptance.",
      "fix": "Define budget semantics precisely: (1) enforce a hard total ensemble budget and independent per-model caps; (2) for `best_of_n`, do not abort others when one hits its cap—only abort that model; (3) implement streaming token accounting where supported (Anthropic usage deltas / provider token callbacks) or enforce conservative max_tokens derived from remaining budget; (4) ensure abort propagation is per-invocation with a parent AbortController for the ensemble."
    }
  ],
  "question": "",
  "iteration": 1
}
