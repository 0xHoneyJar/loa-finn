#!/usr/bin/env bash
# test-pipeline-smoke.sh — Smoke test for the /ground-truth document generation pipeline
# Verifies: template dispatch, quality gates, JSON schema, metrics append.
# Per SDD Sprint 1 acceptance gate: dry-run one module doc through full pipeline.
#
# Usage: test-pipeline-smoke.sh [--json] [--verbose]
#
# Exit codes:
#   0 = All smoke tests pass
#   1 = One or more smoke tests failed
#   2 = Configuration error

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
TEMPLATE_DIR=".claude/skills/ground-truth/resources/templates"
JSON_OUTPUT=false
VERBOSE=false

for arg in "$@"; do
  case "$arg" in
    --json) JSON_OUTPUT=true ;;
    --verbose) VERBOSE=true ;;
  esac
done

passed=0
failed=0
results="["
first=true

run_test() {
  local name="$1"
  local description="$2"
  shift 2

  if ! $first; then results+=","; fi
  first=false

  local exit_code=0
  local output=""
  output=$("$@" 2>&1) || exit_code=$?

  local status="pass"
  if [[ $exit_code -ne 0 ]]; then
    status="fail"
    ((failed++)) || true
  else
    ((passed++)) || true
  fi

  results+='{"test":"'"$name"'","description":"'"$description"'","status":"'"$status"'","exit_code":'"$exit_code"'}'

  if $VERBOSE; then
    echo "  [$status] $name: $description"
    if [[ $exit_code -ne 0 && -n "$output" ]]; then
      echo "    Output: $(echo "$output" | head -3)"
    fi
  fi
}

echo "Running pipeline smoke tests..."

# ── Test 1: All 8 new templates exist ──
for tpl in readme module-doc operations-guide api-reference security-doc contributing changelog index; do
  run_test "template-exists-$tpl" "Template $tpl.md exists" \
    test -f "$TEMPLATE_DIR/$tpl.md"
done

# ── Test 2: Pre-existing templates still exist ──
run_test "template-exists-architecture-overview" "Pre-existing architecture-overview.md exists" \
  test -f "$TEMPLATE_DIR/architecture-overview.md"
run_test "template-exists-capability-brief" "Pre-existing capability-brief.md exists" \
  test -f "$TEMPLATE_DIR/capability-brief.md"

# ── Test 3: All templates have TEMPLATE-META blocks ──
for tpl in readme module-doc operations-guide api-reference security-doc contributing changelog index; do
  run_test "template-meta-$tpl" "Template $tpl.md has TEMPLATE-META block" \
    grep -q "TEMPLATE-META" "$TEMPLATE_DIR/$tpl.md"
done

# ── Test 4: Quality gate scripts exist and are executable ──
for script in check-agent-context.sh verify-citations.sh check-provenance.sh check-claim-grounding.sh scan-banned-terms.sh check-links.sh export-gate-metrics.sh; do
  run_test "gate-exists-$script" "Gate script $script exists and is executable" \
    test -x "$SCRIPT_DIR/$script"
done

# ── Test 5: quality-gates.sh runs without crashing on a test doc ──
# Create a minimal valid test document
test_doc=$(mktemp /tmp/smoke-test-XXXXXX.md)
cat > "$test_doc" << 'TESTEOF'
# Test Document

> Generated by Ground Truth v1.0.0 | 2026-01-01

<!-- AGENT-CONTEXT: name=test, type=overview, purpose=Smoke test document, key_files=README.md, version=0000000000000000000000000000000000000000 -->

## Section One

<!-- provenance: CODE-FACTUAL -->
<!-- evidence: symbol=test -->
This is a test section with a citation to `README.md:1`.

<!-- ground-truth-meta: head_sha=abc123 generated_at=2026-01-01 features_sha=abc limitations_sha=abc ride_sha=abc -->
TESTEOF

run_test "quality-gates-runs" "quality-gates.sh runs without crash on test doc" \
  bash -c "$SCRIPT_DIR/quality-gates.sh '$test_doc' --json >/dev/null 2>&1; true"

# ── Test 6: quality-gates.sh produces valid JSON ──
# Capture metrics line count BEFORE running quality-gates.sh for Test 8
metrics_file="grimoires/loa/ground-truth/gate-metrics.jsonl"
if [[ -f "$metrics_file" ]]; then
  line_count_before=$(wc -l < "$metrics_file")
else
  line_count_before=0
fi

gate_output_file=$(mktemp /tmp/gate-output-XXXXXX.json)
"$SCRIPT_DIR/quality-gates.sh" "$test_doc" --json > "$gate_output_file" 2>/dev/null || true
run_test "quality-gates-json" "quality-gates.sh produces valid JSON" \
  jq . "$gate_output_file"

# ── Test 7: JSON output has required fields ──
run_test "quality-gates-schema" "quality-gates.sh JSON has required fields (passed, gates, violations)" \
  jq -e '.passed != null and .gates != null' "$gate_output_file"
rm -f "$gate_output_file"

# ── Test 8: Metrics file gets appended ──
# line_count_before was captured above, before the quality-gates.sh run
if [[ -f "$metrics_file" ]]; then
  line_count_after=$(wc -l < "$metrics_file")
  run_test "metrics-append" "export-gate-metrics.sh appended to gate-metrics.jsonl" \
    test "$line_count_after" -gt "$line_count_before"
else
  run_test "metrics-append" "export-gate-metrics.sh appended to gate-metrics.jsonl" \
    false
fi

# ── Test 9: Banned security terms file exists ──
run_test "banned-security-terms-exists" "banned-security-terms.txt exists" \
  test -f "grimoires/loa/ground-truth/banned-security-terms.txt"

# ── Test 10: Banned security allowlist exists ──
run_test "banned-security-allow-exists" "banned-security-allow.txt exists" \
  test -f "grimoires/loa/ground-truth/banned-security-allow.txt"

# ── Test 11: update-generation-manifest.sh exists ──
run_test "manifest-script-exists" "update-generation-manifest.sh exists and is executable" \
  test -x "$SCRIPT_DIR/update-generation-manifest.sh"

# Cleanup
rm -f "$test_doc"

results+="]"

# ── Output ──
total=$((passed + failed))
if $JSON_OUTPUT; then
  echo '{"total":'"$total"',"passed":'"$passed"',"failed":'"$failed"',"results":'"$results"'}'
else
  echo ""
  echo "Pipeline Smoke Test: $passed/$total passed"
  if [[ $failed -gt 0 ]]; then
    echo "FAILED:"
    echo "$results" | jq -r '.[] | select(.status == "fail") | "  \(.test): \(.description)"' 2>/dev/null || true
  fi
fi

if [[ $failed -gt 0 ]]; then
  exit 1
else
  exit 0
fi
